# üß† SCC0270 - Redes Neurais

Reposit√≥rio com os projetos da disciplina **SCC0270 - Redes Neurais e Aprendizado Profundo**, oferecida pelo ICMC - USP S√£o Carlos, 2025.

## üîß Configura√ß√£o do Ambiente

Este projeto utiliza o gerenciador de ambientes e depend√™ncias [`uv`](https://github.com/astral-sh/uv).  
Para configurar o ambiente corretamente, siga os passos abaixo:

### 1. Instale o `uv`

Se ainda n√£o tiver o `uv` instalado, execute:

```bash
curl -Ls https://astral.sh/uv/install.sh | bash
```

### 2. Crie e sincronize o ambiente virtual

Para criar um ambiente virtual e instalar todas as depend√™ncias listadas no `pyproject.toml`, execute:

```bash
uv sync
```

Este comando cria automaticamente o ambiente virtual e instala as bibliotecas necess√°rias.

---

## üìÇ Organiza√ß√£o do Reposit√≥rio

- `data/` ‚Äî üì¶ Dados utilizados nos projetos  
- `notebooks/` ‚Äî üìí Notebooks de desenvolvimento e an√°lise  
- `model/` - üîß Modelos ResNet50
- `posters/` ‚Äî üñºÔ∏è Material gr√°fico (p√¥steres e apresenta√ß√µes)  
- `assets/` ‚Äî üìÅ Arquivos auxiliares como imagens usadas no README  

---

# Projetos

Os projetos s√£o baseados no seguinte paper ["MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications"](https://arxiv.org/html/2407.02994v1#S3)

O objetivo dos autores foi construir um conjunto de dados melhor estruturado com imagens m√©dicas e informa√ß√µes cl√≠nicas associadas a cada imagem a fim de disponibilizar uma fonte de dados para que pesquisadores e profissionais da sa√∫de possam, a partir desses dados, construir solu√ß√µes de IA para a √°rea m√©dica uma vez que um conjunto de dados padronizado est√° dispon√≠vel.

A principal motiva√ß√£o dos autores deve-se ao fato de que a maioria dos dados m√©dicos s√£o privados e, at√© a publica√ß√£o do trabalho, inexistiam conjuntos de dados m√©dicos abertos cuja estrutura permitisse o desenvolvimento de solu√ß√µes baseadas em IA.

## Dados (MedPix 2.0)

Este projeto utiliza o conjunto de dados **MedPix 2.0**, uma base de dados biom√©dica multimodal abrangente e de alta qualidade, desenvolvida para aplica√ß√µes avan√ßadas de Intelig√™ncia Artificial (IA) no dom√≠nio m√©dico. Origin√°ria da conhecida base de dados MedPix¬Æ (utilizada para Educa√ß√£o M√©dica Continuada), a MedPix 2.0 foi criada para superar a escassez de datasets m√©dicos de alta qualidade e de acesso p√∫blico, especialmente para o desenvolvimento de Modelos de Linguagem de Grande Porte Multimodais (MLLM).

A constru√ß√£o do MedPix 2.0 envolveu um **pipeline semi-autom√°tico para a extra√ß√£o de dados visuais e textuais**, seguido por um **processo de curadoria manual** para remover amostras ruidosas. Os dados s√£o armazenados em uma **base de dados n√£o-relacional MongoDB**, que reorganiza a estrutura do MedPix¬Æ original, tornando-a mais acess√≠vel e estruturada para aplica√ß√µes de IA.

### Estrutura dos Dados

A MedPix 2.0 integra **dados visuais (scans de Tomografia Computadorizada - TC e Resson√¢ncia Magn√©tica - RM)** e **dados textuais (relat√≥rios cl√≠nicos e achados)**. Cada caso cl√≠nico dentro do dataset cont√©m ao menos uma imagem m√©dica e as informa√ß√µes correspondentes, como achados, notas de discuss√£o, diagn√≥stico, diagn√≥stico diferencial, tratamento e acompanhamento, todas apresentadas em um formato semi-estruturado JSON.

Na implementa√ß√£o do MongoDB, os dados s√£o organizados em duas cole√ß√µes principais:

- **`Image_Descriptions`**: Cont√©m **documentos de descri√ß√£o (`descriptions documents`)**, que armazenam informa√ß√µes estritamente conectadas √†s imagens. Estes documentos incluem detalhes como a modalidade do exame (CT ou MR) e a parte do corpo (Location).
- **`Clinical_reports`**: Cont√©m **documentos de caso-t√≥pico (`case-topic documents`)**, que agrupam informa√ß√µes detalhadas de um caso cl√≠nico completo, incluindo explica√ß√µes acad√™micas e gerais sobre a doen√ßa investigada.

Existe uma rela√ß√£o de um-para-muitos entre os casos cl√≠nicos e as imagens, onde o identificador √∫nico (`U_id`) de um documento de caso-t√≥pico √© incorporado em cada documento de descri√ß√£o de imagem a ele relacionado. As imagens em si s√£o armazenadas na pasta `MedPix-2.0/images/` e acessadas via URL.

### Divis√£o e Acesso aos Dados no Projeto

Para este projeto, um subconjunto dos dados da MedPix 2.0 foi dividido em **conjuntos de treinamento e teste** e est√£o presentes na pasta `MedPix-2.0/splitted_dataset/`. Os dados s√£o fornecidos em arquivos JSON, que seguem a estrutura dos documentos descritos acima. Exemplos desses arquivos incluem:

- **`descriptions_train.jsonl`**: Documentos de descri√ß√£o para o conjunto de treinamento.
- **`data_train.jsonl`**: Documentos de caso-t√≥pico para o conjunto de treinamento.
- **`descriptions_test.jsonl`**: Documentos de descri√ß√£o para o conjunto de teste.
- **`data_test.jsonl`**: Documentos de caso-t√≥pico para o conjunto de teste.

Essa estrutura√ß√£o de dados facilita o uso direto para o treinamento e fine-tuning de modelos de Machine Learning e Deep Learning, sem a necessidade de pr√©-processamento adicional para tarefas multimodais. A base de dados MedPix 2.0, com sua curadoria e estrutura√ß√£o, √© um ponto de partida relevante para o desenvolvimento de sistemas de IA multimodal no dom√≠nio m√©dico, incluindo sistemas de extra√ß√£o de informa√ß√£o, an√°lise automatizada de imagens e modelos de IA generativa para relat√≥rios cl√≠nicos.

O c√≥digo-fonte do projeto e os dados utilizados para teste e treinamento est√£o **dispon√≠veis gratuitamente** nos reposit√≥rios p√∫blicos indicados no artigo original.

## üöÄ Projeto 01

üìÖ **Prazo:** 21/06/2025  

**Tarefas:**  

- üîç Classificador bin√°rio de **Modalidade** (`CT` ou `MR`)  
- üß† Classificador multi-classe de **Localidade** (21 classes)  

O objetivo do Projeto 01 √© construir um classificador bin√°rio capaz de classificar as imagens como `CT` (Tomografia Computadorizada) ou `MR` (Resson√¢ncia Magn√©tica) e tamb√©m um classificador multi-classe para classificar as Localidades associadas a cada imagem. S√£o 21 Localidades dispon√≠veis: `Chest, Pulmonary`, `Genitourinary`, `Head and Neck`, `Cardiovascular`, `Brain and Neuro`, `Abdomen`, `Spine`, `Eye and Orbit`, `Gastrointestinal`, `Vascular`, `Endocrine`, `Musculoskeletal`, `Pathology`, `Generalized`, `Hematopoietic`, `Dental, Oral, or Tooth`, `Nerve, central`, `Breast and Mammography`, `Bethesda, MD`, `Ophthalmology`, `Nerve, peripheral`.

De in√≠cio, no notebook `Trabalho_01_ML.ipynb` foram constru√≠dos modelos de ML cl√°ssicos baseados em t√©cnicas de extra√ß√£o de caracter√≠sticas como Descritores de Texturas e Cores e em seguida, ajustou-se um KNN.
No notebook presente no Colab no seguinte [Notebook com treino da CNN para Modalidade no Colab](https://drive.google.com/drive/folders/1nnpJwP1hIiqQjFYWDabOCFGvpeqj7dPg?usp=drive_link) fez-se o fine-tuning de uma ResNet50 para a classifica√ß√£o da modalidade e no notebook [Notebook com treino da CNN para Localidade no Colab](https://colab.research.google.com/drive/1X9ANeqFUI9rEleWq8OYalE2q5EnB3cQ_?usp=drive_link) fez-se o fine-tuning de uma ResNet50 para a classifica√ß√£o da localidade.

O c√≥digo para carregamento do modelo treinado e c√°lculo das m√©tricas de avalia√ß√£o est√£o presentes no notebook `Trabalho_01_CNN.ipynb`.

Obtivemos os seguintes resultados na tarefa de classifica√ß√£o bin√°ria:

## Resultados Classifica√ß√£o da Modalidade

### KNN + Descritores de Textura

| Class        | Precision | Recall | F1-Score | Support |
|--------------|-----------|--------|----------|---------|
| MR           | 0.00      | 0.00   | 0.00     | 100     |
| CT           | 0.50      | 1.00   | 0.67     | 100     |
| **Accuracy** |           |        | 0.50     | 200     |
| **Macro Avg**| 0.25      | 0.50   | 0.33     | 200     |
| **Weighted Avg** | 0.25  | 0.50   | 0.33     | 200     |

### KNN + Descritores de Imagem

| Class          | Precision | Recall | F1-Score | Support |
|----------------|-----------|--------|----------|---------|
| MR             | 0.60      | 0.64   | 0.62     | 100     |
| CT             | 0.62      | 0.58   | 0.60     | 100     |
| **Accuracy**   |           |        | 0.61     | 200     |
| **Macro Avg**  | 0.61      | 0.61   | 0.61     | 200     |
| **Weighted Avg**| 0.61     | 0.61   | 0.61     | 200     |

### KNN + Descritores de Textura + Imagem

| Class           | Precision | Recall | F1-Score | Support |
|-----------------|-----------|--------|----------|---------|
| MR               | 0.00      | 0.00   | 0.00     | 100     |
| CT               | 0.50      | 1.00   | 0.67     | 100     |
| **Accuracy**     |           |        | 0.50     | 200     |
| **Macro Avg**    | 0.25      | 0.50   | 0.33     | 200     |
| **Weighted Avg** | 0.25      | 0.50   | 0.33     | 200     |

### Fine-tuning ResNet50 (02 epochs)

| Class           | Precision | Recall | F1-Score | Support |
|-----------------|-----------|--------|----------|---------|
| MR               | 0.99      | 0.98   | 0.98     | 100     |
| CT               | 0.98      | 0.99   | 0.99     | 100     |
| **Accuracy**     |           |        | 0.98     | 200     |
| **Macro Avg**    | 0.99      | 0.98   | 0.98     | 200     |
| **Weighted Avg** | 0.99      | 0.98   | 0.98     | 200     |

## Resultados Classifica√ß√£o da Localidade (ResNet50 - 02 Epochs)

M√©todos de ML com descritores de textura e cores n√£o foram capazes de classificar a Localidade das imagens.
Foi treinado, do mesmo modo, uma ResNet50 para a classifica√ß√£o das 21 localidades.

| Label                  | Precision | Recall | F1-Score | Support |
|------------------------|-----------|--------|----------|---------|
| Chest, Pulmonary       | 0.00      | 0.00   | 0.00     | 1       |
| Genitourinary          | 0.68      | 0.94   | 0.79     | 51      |
| Head and Neck          | 0.00      | 0.00   | 0.00     | 4       |
| Cardiovascular         | 0.00      | 0.00   | 0.00     | 1       |
| Brain and Neuro        | 0.70      | 0.88   | 0.78     | 24      |
| Eye and Orbit          | 1.00      | 0.29   | 0.44     | 7       |
| Gastrointestinal       | 0.75      | 0.29   | 0.42     | 31      |
| Vascular               | 0.00      | 0.00   | 0.00     | 10      |
| Pathology              | 0.18      | 0.27   | 0.21     | 11      |
| Spine                  | 0.43      | 0.30   | 0.35     | 10      |
| Endocrine              | 0.48      | 0.71   | 0.57     | 14      |
| Nerve, central         | 0.00      | 0.00   | 0.00     | 4       |
| Musculoskeletal        | 0.82      | 0.69   | 0.75     | 26      |
| Abdomen                | 0.00      | 0.00   | 0.00     | 6       |
| **Accuracy**           |           |        | **0.57** | 200     |
| **Macro Avg**          | 0.36      | 0.31   | 0.31     | 200     |
| **Weighted Avg**       | 0.58      | 0.57   | 0.54     | 200     |

Obtivemos uma **acur√°cia de 57%** que √© ligeiramente superior √† reportada pelos autores de 52.5%.  
Como nem todas as classes est√£o presentes no conjunto de teste, a tabela acima n√£o apresenta todas as classes.
Percebe-se que as Localidades com menos exemplos dispon√≠veis no conjunto de treinamento apresentam menores valores de acur√°cia, o que √© o esperado.
N√£o observamos melhoras significativas com o aumento do n√∫mero de epochs acima de 2.

---

## üöß Projeto 02

üóìÔ∏è **Prazo:** 09/07/2025\
üîÑ **Classificador Multimodal com CLIP**

O objetivo do Projeto 02 foi desenvolver um classificador de **Localidade Anat√¥mica** utilizando uma abordagem **multimodal**, combinando informa√ß√µes visuais (imagem m√©dica) e textuais (legenda associada) por meio do modelo **CLIP (Contrastive Language-Image Pretraining)** da OpenAI.

Inicialmente, um dataset customizado foi criado a partir dos arquivos JSON da MedPix 2.0, contendo a associa√ß√£o entre imagem, legenda (`Caption`) e localiza√ß√£o anat√¥mica (`Location`). Os dados foram processados e divididos em conjuntos de treino e teste, com as imagens sendo carregadas e processadas juntamente com os textos utilizando o `CLIPProcessor`.

O modelo foi constru√≠do em duas etapas:

- Extra√ß√£o dos **embeddings** de imagem e texto via modelo pr√©-treinado `clip-vit-base-patch32`;
- Treinamento de um **classificador simples** com camadas lineares sobre a concatena√ß√£o dos embeddings.

---

### üìà Curvas de Treinamento

Durante as 30 √©pocas, observou-se uma **queda consistente nas perdas de treino e valida√ß√£o**, sem sinais de overfitting.

| √âpoca | Loss Treino | Loss Valida√ß√£o |
| ----- | ----------- | -------------- |
| 1     | 2.7800      | 2.4204         |
| 10    | 1.3309      | 1.3012         |
| 20    | 1.0183      | 1.0025         |
| 30    | 0.8183      | 0.8064         |

> üîç A diferen√ßa entre as curvas foi pequena durante todo o treinamento, indicando boa generaliza√ß√£o. Mesmo ap√≥s 30 √©pocas, ambas ainda apresentam tend√™ncia de queda.

---

### üìã Resultados por Classe (classification\_report)

O modelo alcan√ßou uma **acur√°cia total de 78%**, superando a baseline de 52.5% reportada no artigo original. Abaixo est√£o os principais resultados por classe:

```markdown
| Classe                    | Precision | Recall | F1-Score | Suporte |
|---------------------------|-----------|--------|----------|---------|
| Brain and Neuro           | 0.80      | 0.97   | 0.88     | 522     |
| Musculoskeletal           | 0.85      | 0.95   | 0.89     | 209     |
| Chest, Pulmonary          | 0.79      | 0.95   | 0.86     | 187     |
| Gastrointestinal          | 0.65      | 0.95   | 0.77     | 154     |
| Genitourinary             | 0.71      | 0.83   | 0.77     | 120     |
| Cardiovascular            | 0.89      | 0.66   | 0.76     | 50      |
| Spine                     | 0.78      | 0.65   | 0.70     | 48      |
| Eye and Orbit             | 0.88      | 0.57   | 0.69     | 49      |
| Head and Neck             | 0.77      | 0.58   | 0.66     | 76      |
| Generalized               | 1.00      | 0.11   | 0.19     | 56      |
| Abdomen                   | 1.00      | 0.10   | 0.17     | 42      |
| Vascular                  | 0.82      | 0.27   | 0.41     | 66      |
| Classes com suporte < 10  | 0.00      | 0.00   | 0.00     | -       |

|                           |           |        |          |         |
| **Acur√°cia total**        |           |        | **0.78** | 1653    |
| **M√©dia Macro**           | 0.47      | 0.36   | 0.37     |         |
| **M√©dia Ponderada**       | 0.76      | 0.78   | 0.74     |         |
```

> üìå **An√°lise:**
>
> - O modelo se saiu muito bem em classes com maior volume de dados (e.g., `Brain and Neuro`, `Musculoskeletal`).
> - Classes com poucos exemplos tiveram desempenho muito baixo ou nulo, como esperado.
> - A **m√©dia ponderada** mostra que, mesmo com desbalanceamento, o modelo foi eficaz na tarefa geral de classifica√ß√£o multimodal.

---

## üéØ Projeto 03

üìÖ **Prazo:** 11/06/2025  

Atividade Extensionista no campus da USP - S√£o Carlos (ICMC) com apresenta√ß√£o do p√¥ster:  
üñºÔ∏è **"Como as m√°quinas enxergam?"**  

**Arquivo:** `posters/Poster Rede Neurais - Final.pptx`  

**Imagem do P√¥ster**  
![poster-image](assets/imagem_poster.png)  

---

## üë• Integrantes

- Brunna Quatrochi [üîó LinkedIn](https://www.linkedin.com/in/brunna-quatrochi/)
- Gabriela dos Santos Amaral üêô [GitHub](https://github.com/GabrielaSAmaral) | [üîó LinkedIn](https://www.linkedin.com/in/gabriela-amaral-ga/)
- Heitor Carvalho Pinheiro üêô [GitHub](https://github.com/Heitorcp) | [üîó LinkedIn](https://www.linkedin.com/in/heitor-cp/)
- Ivan Barbosa Pinto üêô [GitHub](https://github.com/ivpinheiro) | [üîó LinkedIn](https://www.linkedin.com/in/ivanpinheiro/)
- Jo√£o Pedro Serpellone
- Leo Gianotti [üîó LinkedIn](https://www.linkedin.com/in/leo-gianotti-48124a20a/)
- Matheus Chaves Silva [üîó LinkedIn](https://www.linkedin.com/in/matheus-chaves-silva-86425913a/)
- Murilo Valentim Zabott
