# ğŸ§  SCC0270 - Redes Neurais

RepositÃ³rio com os projetos da disciplina **SCC0270 - Redes Neurais e Aprendizado Profundo**, oferecida pelo ICMC - USP SÃ£o Carlos, 2025.

## ğŸ”§ ConfiguraÃ§Ã£o do Ambiente

Este projeto utiliza o gerenciador de ambientes e dependÃªncias [`uv`](https://github.com/astral-sh/uv).  
Para configurar o ambiente corretamente, siga os passos abaixo:

### 1. Instale o `uv`

Se ainda nÃ£o tiver o `uv` instalado, execute:

```bash
curl -Ls https://astral.sh/uv/install.sh | bash
```

### 2. Crie e sincronize o ambiente virtual

Para criar um ambiente virtual e instalar todas as dependÃªncias listadas no `pyproject.toml`, execute:

```bash
uv sync
```

Este comando cria automaticamente o ambiente virtual e instala as bibliotecas necessÃ¡rias.

---

## ğŸ“‚ OrganizaÃ§Ã£o do RepositÃ³rio

- `data/` â€” ğŸ“¦ Dados utilizados nos projetos  
- `notebooks/` â€” ğŸ“’ Notebooks de desenvolvimento e anÃ¡lise  
- `model/` - ğŸ”§ Modelos ResNet50
- `posters/` â€” ğŸ–¼ï¸ Material grÃ¡fico (pÃ´steres e apresentaÃ§Ãµes)  
- `assets/` â€” ğŸ“ Arquivos auxiliares como imagens usadas no README  

---

# Projetos

Os projetos sÃ£o baseados no seguinte paper ["MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications"](https://arxiv.org/html/2407.02994v1#S3)

O objetivo dos autores foi construir um conjunto de dados melhor estruturado com imagens mÃ©dicas e informaÃ§Ãµes clÃ­nicas associadas a cada imagem a fim de disponibilizar uma fonte de dados para que pesquisadores e profissionais da saÃºde possam, a partir desses dados, construir soluÃ§Ãµes de IA para a Ã¡rea mÃ©dica uma vez que um conjunto de dados padronizado estÃ¡ disponÃ­vel.

A principal motivaÃ§Ã£o dos autores deve-se ao fato de que a maioria dos dados mÃ©dicos sÃ£o privados e, atÃ© a publicaÃ§Ã£o do trabalho, inexistiam conjuntos de dados mÃ©dicos abertos cuja estrutura permitisse o desenvolvimento de soluÃ§Ãµes baseadas em IA.

## Dados (MedPix 2.0)

Este projeto utiliza o conjunto de dados **MedPix 2.0**, uma base de dados biomÃ©dica multimodal abrangente e de alta qualidade, desenvolvida para aplicaÃ§Ãµes avanÃ§adas de InteligÃªncia Artificial (IA) no domÃ­nio mÃ©dico. OriginÃ¡ria da conhecida base de dados MedPixÂ® (utilizada para EducaÃ§Ã£o MÃ©dica Continuada), a MedPix 2.0 foi criada para superar a escassez de datasets mÃ©dicos de alta qualidade e de acesso pÃºblico, especialmente para o desenvolvimento de Modelos de Linguagem de Grande Porte Multimodais (MLLM).

A construÃ§Ã£o do MedPix 2.0 envolveu um **pipeline semi-automÃ¡tico para a extraÃ§Ã£o de dados visuais e textuais**, seguido por um **processo de curadoria manual** para remover amostras ruidosas. Os dados sÃ£o armazenados em uma **base de dados nÃ£o-relacional MongoDB**, que reorganiza a estrutura do MedPixÂ® original, tornando-a mais acessÃ­vel e estruturada para aplicaÃ§Ãµes de IA.

### Estrutura dos Dados

A MedPix 2.0 integra **dados visuais (scans de Tomografia Computadorizada - TC e RessonÃ¢ncia MagnÃ©tica - RM)** e **dados textuais (relatÃ³rios clÃ­nicos e achados)**. Cada caso clÃ­nico dentro do dataset contÃ©m ao menos uma imagem mÃ©dica e as informaÃ§Ãµes correspondentes, como achados, notas de discussÃ£o, diagnÃ³stico, diagnÃ³stico diferencial, tratamento e acompanhamento, todas apresentadas em um formato semi-estruturado JSON.

Na implementaÃ§Ã£o do MongoDB, os dados sÃ£o organizados em duas coleÃ§Ãµes principais:

- **`Image_Descriptions`**: ContÃ©m **documentos de descriÃ§Ã£o (`descriptions documents`)**, que armazenam informaÃ§Ãµes estritamente conectadas Ã s imagens. Estes documentos incluem detalhes como a modalidade do exame (CT ou MR) e a parte do corpo (Location).
- **`Clinical_reports`**: ContÃ©m **documentos de caso-tÃ³pico (`case-topic documents`)**, que agrupam informaÃ§Ãµes detalhadas de um caso clÃ­nico completo, incluindo explicaÃ§Ãµes acadÃªmicas e gerais sobre a doenÃ§a investigada.

Existe uma relaÃ§Ã£o de um-para-muitos entre os casos clÃ­nicos e as imagens, onde o identificador Ãºnico (`U_id`) de um documento de caso-tÃ³pico Ã© incorporado em cada documento de descriÃ§Ã£o de imagem a ele relacionado. As imagens em si sÃ£o armazenadas na pasta `MedPix-2.0/images/` e acessadas via URL.

### DivisÃ£o e Acesso aos Dados no Projeto

Para este projeto, um subconjunto dos dados da MedPix 2.0 foi dividido em **conjuntos de treinamento e teste** e estÃ£o presentes na pasta `MedPix-2.0/splitted_dataset/`. Os dados sÃ£o fornecidos em arquivos JSON, que seguem a estrutura dos documentos descritos acima. Exemplos desses arquivos incluem:

- **`descriptions_train.jsonl`**: Documentos de descriÃ§Ã£o para o conjunto de treinamento.
- **`data_train.jsonl`**: Documentos de caso-tÃ³pico para o conjunto de treinamento.
- **`descriptions_test.jsonl`**: Documentos de descriÃ§Ã£o para o conjunto de teste.
- **`data_test.jsonl`**: Documentos de caso-tÃ³pico para o conjunto de teste.

Essa estruturaÃ§Ã£o de dados facilita o uso direto para o treinamento e fine-tuning de modelos de Machine Learning e Deep Learning, sem a necessidade de prÃ©-processamento adicional para tarefas multimodais. A base de dados MedPix 2.0, com sua curadoria e estruturaÃ§Ã£o, Ã© um ponto de partida relevante para o desenvolvimento de sistemas de IA multimodal no domÃ­nio mÃ©dico, incluindo sistemas de extraÃ§Ã£o de informaÃ§Ã£o, anÃ¡lise automatizada de imagens e modelos de IA generativa para relatÃ³rios clÃ­nicos.

O cÃ³digo-fonte do projeto e os dados utilizados para teste e treinamento estÃ£o **disponÃ­veis gratuitamente** nos repositÃ³rios pÃºblicos indicados no artigo original.

## ğŸš€ Projeto 01

ğŸ“… **Prazo:** 21/06/2025  

**Tarefas:**  

- ğŸ” Classificador binÃ¡rio de **Modalidade** (`CT` ou `MR`)  
- ğŸ§  Classificador multi-classe de **Localidade** (21 classes)  

O objetivo do Projeto 01 Ã© construir um classificador binÃ¡rio capaz de classificar as imagens como `CT` (Tomografia Computadorizada) ou `MR` (RessonÃ¢ncia MagnÃ©tica) e tambÃ©m um classificador multi-classe para classificar as Localidades associadas a cada imagem. SÃ£o 21 Localidades disponÃ­veis: `Chest, Pulmonary`, `Genitourinary`, `Head and Neck`, `Cardiovascular`, `Brain and Neuro`, `Abdomen`, `Spine`, `Eye and Orbit`, `Gastrointestinal`, `Vascular`, `Endocrine`, `Musculoskeletal`, `Pathology`, `Generalized`, `Hematopoietic`, `Dental, Oral, or Tooth`, `Nerve, central`, `Breast and Mammography`, `Bethesda, MD`, `Ophthalmology`, `Nerve, peripheral`.

De inÃ­cio, no notebook `Trabalho_01_ML.ipynb` foram construÃ­dos modelos de ML clÃ¡ssicos baseados em tÃ©cnicas de extraÃ§Ã£o de caracterÃ­sticas como Descritores de Texturas e Cores e em seguida, ajustou-se um KNN.
No notebook presente no Colab no seguinte [Notebook com treino da CNN para Modalidade no Colab](https://drive.google.com/drive/folders/1nnpJwP1hIiqQjFYWDabOCFGvpeqj7dPg?usp=drive_link) fez-se o fine-tuning de uma ResNet50 para a classificaÃ§Ã£o da modalidade e no notebook [Notebook com treino da CNN para Localidade no Colab](https://colab.research.google.com/drive/1X9ANeqFUI9rEleWq8OYalE2q5EnB3cQ_?usp=drive_link) fez-se o fine-tuning de uma ResNet50 para a classificaÃ§Ã£o da localidade.

O cÃ³digo para carregamento do modelo treinado e cÃ¡lculo das mÃ©tricas de avaliaÃ§Ã£o estÃ£o presentes no notebook `Trabalho_01_CNN.ipynb`.

Obtivemos os seguintes resultados na tarefa de classificaÃ§Ã£o binÃ¡ria:

## Resultados ClassificaÃ§Ã£o da Modalidade

### KNN + Descritores de Textura

| Class        | Precision | Recall | F1-Score | Support |
|--------------|-----------|--------|----------|---------|
| MR           | 0.00      | 0.00   | 0.00     | 100     |
| CT           | 0.50      | 1.00   | 0.67     | 100     |
| **Accuracy** |           |        | 0.50     | 200     |
| **Macro Avg**| 0.25      | 0.50   | 0.33     | 200     |
| **Weighted Avg** | 0.25  | 0.50   | 0.33     | 200     |

### KNN + Descritores de Imagem

| Class          | Precision | Recall | F1-Score | Support |
|----------------|-----------|--------|----------|---------|
| MR             | 0.60      | 0.64   | 0.62     | 100     |
| CT             | 0.62      | 0.58   | 0.60     | 100     |
| **Accuracy**   |           |        | 0.61     | 200     |
| **Macro Avg**  | 0.61      | 0.61   | 0.61     | 200     |
| **Weighted Avg**| 0.61     | 0.61   | 0.61     | 200     |

### KNN + Descritores de Textura + Imagem

| Class           | Precision | Recall | F1-Score | Support |
|-----------------|-----------|--------|----------|---------|
| MR               | 0.00      | 0.00   | 0.00     | 100     |
| CT               | 0.50      | 1.00   | 0.67     | 100     |
| **Accuracy**     |           |        | 0.50     | 200     |
| **Macro Avg**    | 0.25      | 0.50   | 0.33     | 200     |
| **Weighted Avg** | 0.25      | 0.50   | 0.33     | 200     |

### Fine-tuning ResNet50 (02 epochs)

| Class           | Precision | Recall | F1-Score | Support |
|-----------------|-----------|--------|----------|---------|
| MR               | 0.99      | 0.98   | 0.98     | 100     |
| CT               | 0.98      | 0.99   | 0.99     | 100     |
| **Accuracy**     |           |        | 0.98     | 200     |
| **Macro Avg**    | 0.99      | 0.98   | 0.98     | 200     |
| **Weighted Avg** | 0.99      | 0.98   | 0.98     | 200     |

## Resultados ClassificaÃ§Ã£o da Localidade (ResNet50 - 02 Epochs)

MÃ©todos de ML com descritores de textura e cores nÃ£o foram capazes de classificar a Localidade das imagens.
Foi treinado, do mesmo modo, uma ResNet50 para a classificaÃ§Ã£o das 21 localidades.

| Label                  | Precision | Recall | F1-Score | Support |
|------------------------|-----------|--------|----------|---------|
| Chest, Pulmonary       | 0.00      | 0.00   | 0.00     | 1       |
| Genitourinary          | 0.68      | 0.94   | 0.79     | 51      |
| Head and Neck          | 0.00      | 0.00   | 0.00     | 4       |
| Cardiovascular         | 0.00      | 0.00   | 0.00     | 1       |
| Brain and Neuro        | 0.70      | 0.88   | 0.78     | 24      |
| Eye and Orbit          | 1.00      | 0.29   | 0.44     | 7       |
| Gastrointestinal       | 0.75      | 0.29   | 0.42     | 31      |
| Vascular               | 0.00      | 0.00   | 0.00     | 10      |
| Pathology              | 0.18      | 0.27   | 0.21     | 11      |
| Spine                  | 0.43      | 0.30   | 0.35     | 10      |
| Endocrine              | 0.48      | 0.71   | 0.57     | 14      |
| Nerve, central         | 0.00      | 0.00   | 0.00     | 4       |
| Musculoskeletal        | 0.82      | 0.69   | 0.75     | 26      |
| Abdomen                | 0.00      | 0.00   | 0.00     | 6       |
| **Accuracy**           |           |        | **0.57** | 200     |
| **Macro Avg**          | 0.36      | 0.31   | 0.31     | 200     |
| **Weighted Avg**       | 0.58      | 0.57   | 0.54     | 200     |

Obtivemos uma **acurÃ¡cia de 57%** que Ã© ligeiramente superior Ã  reportada pelos autores de 52.5%.  
Como nem todas as classes estÃ£o presentes no conjunto de teste, a tabela acima nÃ£o apresenta todas as classes.
Percebe-se que as Localidades com menos exemplos disponÃ­veis no conjunto de treinamento apresentam menores valores de acurÃ¡cia, o que Ã© o esperado.
NÃ£o observamos melhoras significativas com o aumento do nÃºmero de epochs acima de 2.

---

## ğŸš§ Projeto 02

ğŸ—“ï¸ **Prazo:** 09/07/2025\
ğŸ”„ **Classificador Multimodal com CLIP**

O objetivo do Projeto 02 foi desenvolver um classificador de **Localidade AnatÃ´mica** utilizando uma abordagem **multimodal**, combinando informaÃ§Ãµes visuais (imagem mÃ©dica) e textuais (legenda associada) por meio do modelo **CLIP (Contrastive Language-Image Pretraining)** da OpenAI.

Inicialmente, um dataset customizado foi criado a partir dos arquivos JSON da MedPix 2.0, contendo a associaÃ§Ã£o entre imagem, legenda (`Caption`) e localizaÃ§Ã£o anatÃ´mica (`Location`). Os dados foram processados e divididos em conjuntos de treino e teste, com as imagens sendo carregadas e processadas juntamente com os textos utilizando o `CLIPProcessor`.

O modelo foi construÃ­do em duas etapas:

- ExtraÃ§Ã£o dos **embeddings** de imagem e texto via modelo prÃ©-treinado `clip-vit-base-patch32`;
- Treinamento de um **classificador simples** com camadas lineares sobre a concatenaÃ§Ã£o dos embeddings.

---

### ğŸ“ˆ Curvas de Treinamento

Durante as 30 Ã©pocas, observou-se uma **queda consistente nas perdas de treino e validaÃ§Ã£o**, sem sinais de overfitting.

| Ã‰poca | Loss Treino | Loss ValidaÃ§Ã£o |
| ----- | ----------- | -------------- |
| 1     | 2.7800      | 2.4204         |
| 10    | 1.3309      | 1.3012         |
| 20    | 1.0183      | 1.0025         |
| 30    | 0.8183      | 0.8064         |

> ğŸ” A diferenÃ§a entre as curvas foi pequena durante todo o treinamento, indicando boa generalizaÃ§Ã£o. Mesmo apÃ³s 30 Ã©pocas, ambas ainda apresentam tendÃªncia de queda.

---

### ğŸ“‹ Resultados por Classe (classification\_report)

O modelo alcanÃ§ou uma **acurÃ¡cia total de 78%**, superando a baseline de 52.5% reportada no artigo original. Abaixo estÃ£o os principais resultados por classe:

```markdown
| Classe                    | Precision | Recall | F1-Score | Suporte |
|---------------------------|-----------|--------|----------|---------|
| Brain and Neuro           | 0.80      | 0.97   | 0.88     | 522     |
| Musculoskeletal           | 0.85      | 0.95   | 0.89     | 209     |
| Chest, Pulmonary          | 0.79      | 0.95   | 0.86     | 187     |
| Gastrointestinal          | 0.65      | 0.95   | 0.77     | 154     |
| Genitourinary             | 0.71      | 0.83   | 0.77     | 120     |
| Cardiovascular            | 0.89      | 0.66   | 0.76     | 50      |
| Spine                     | 0.78      | 0.65   | 0.70     | 48      |
| Eye and Orbit             | 0.88      | 0.57   | 0.69     | 49      |
| Head and Neck             | 0.77      | 0.58   | 0.66     | 76      |
| Generalized               | 1.00      | 0.11   | 0.19     | 56      |
| Abdomen                   | 1.00      | 0.10   | 0.17     | 42      |
| Vascular                  | 0.82      | 0.27   | 0.41     | 66      |
| Classes com suporte < 10  | 0.00      | 0.00   | 0.00     | -       |

|                           |           |        |          |         |
| **AcurÃ¡cia total**        |           |        | **0.78** | 1653    |
| **MÃ©dia Macro**           | 0.47      | 0.36   | 0.37     |         |
| **MÃ©dia Ponderada**       | 0.76      | 0.78   | 0.74     |         |
```

> ğŸ“Œ **AnÃ¡lise:**
>
> - O modelo se saiu muito bem em classes com maior volume de dados (e.g., `Brain and Neuro`, `Musculoskeletal`).
> - Classes com poucos exemplos tiveram desempenho muito baixo ou nulo, como esperado.
> - A **mÃ©dia ponderada** mostra que, mesmo com desbalanceamento, o modelo foi eficaz na tarefa geral de classificaÃ§Ã£o multimodal.

---

## ğŸ¯ Projeto 03

ğŸ“… **Prazo:** 11/06/2025  

Atividade Extensionista no campus da USP - SÃ£o Carlos (ICMC) com apresentaÃ§Ã£o do pÃ´ster:  
ğŸ–¼ï¸ **"Como as mÃ¡quinas enxergam?"**  

**Arquivo:** `posters/Poster Rede Neurais - Final.pptx`  

**Imagem do PÃ´ster**  
![poster-image](assets/imagem_poster.png)  

---

## ğŸ‘¥ Integrantes

- Brunna Quatrochi [ğŸ”— LinkedIn](https://www.linkedin.com/in/brunna-quatrochi/)
- Gabriela dos Santos Amaral ğŸ™ [GitHub](https://github.com/GabrielaSAmaral) | [ğŸ”— LinkedIn](https://www.linkedin.com/in/gabriela-amaral-ga/)
- Heitor Carvalho Pinheiro ğŸ™ [GitHub](https://github.com/Heitorcp) | [ğŸ”— LinkedIn](https://www.linkedin.com/in/heitor-cp/)
- Ivan Barbosa Pinto ğŸ™ [GitHub](https://github.com/ivpinheiro) | [ğŸ”— LinkedIn](https://www.linkedin.com/in/ivanpinheiro/)
- JoÃ£o Pedro Serpellone
- Leo Gianotti [ğŸ”— LinkedIn](https://www.linkedin.com/in/leo-gianotti-48124a20a/)
- Matheus Chaves Silva [ğŸ”— LinkedIn](https://www.linkedin.com/in/matheus-chaves-silva-86425913a/)
- Murilo Valentim Zabott
